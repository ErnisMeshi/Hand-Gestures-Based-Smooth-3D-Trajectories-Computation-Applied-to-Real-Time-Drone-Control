Robotic systems are increasingly being adopted for filming and photography purposes. By exploiting robots, in fact, it is possible to program complex motions for the camera, achieving high-quality videos/photographs. Our contribution is to propose an alternative to the joystick: being able to control a drone using just a hand and giving space to new ways of expressing video content, even to those who are novices. To achieve this, we capture 3D movements (using a hand tracking system) after building a hand gesture recognition and setting up a solid pipeline to detect 3D trajectories obtained from 2D pixel landmarks, hence estimating the orientation and distance from the camera. Trajectories are interpolated and smoothed with ridge regression. As proof, the captured trajectory was launched on a drone, in simulation, implemented in the ROS framework. The whole pipeline can be easily translated into another kind of task, e.g. interaction and communication in AR / VR.