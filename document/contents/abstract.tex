Robotic systems are increasingly being adopted for filming and photography purposes. By exploiting robots, in fact, it is possible to program complex motions, achieving high-quality videos and photographs. Our contribution is to propose an alternative to the joystick: being able to control a drone using just a hand and giving space to new ways of shooting video content, even to those who are novices. To achieve this, we capture 3D movements, using a hand tracking system, after building a hand gesture recognition and setting up a solid pipeline to detect 3D trajectories obtained from 2D pixel landmarks, hence estimating the orientation and distance from the camera. Trajectories are interpolated and smoothed with ridge regression. As a proof of concept, the captured trajectory was launched first on a drone, in simulation, implemented in the ROS framework, and later on a real drone called DJI Ryze Tello. The whole pipeline can be easily translated into another kind of task, e.g. interaction and communication in AR / VR.