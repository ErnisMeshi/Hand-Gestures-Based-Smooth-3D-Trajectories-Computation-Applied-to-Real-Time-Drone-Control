\chapter*{Introduction}
\addcontentsline{toc}{chapter}{Introduction}
\markboth{}{}
\label{chap:intro}

% https://roboticsandautomationnews.com/2021/12/30/robots-increasingly-taking-over-film-camera-work/48012/
Robots are increasingly taking over from what has traditional been the preserve of human creative people. Progressively film creators are turning to automated systems for recording moving images. Producing new, targeted, and engaging content can be a stressful, time-consuming endeavor. That is why more and more creators and advertisers are embracing tools that take the sting out of the process. Cinema robot not only decreases production time but allow teams to shoot a variety of angles that would be physically impossible or cost a fortune in labor. \\

% https://www.youtube.com/watch?v=CdOaGU04MyM&t=232s
\noindent Unfortunately, it is known that robot programming could be a very time-consuming task. They have to synchronize robot motion with objects in the frame. There are also other requirements that need to be taken into account, such as camera settings (focal length, aperture time and desired depth of field). To speed up the process of robot programming different company as KUKA, partner andyRobot, has developed a plug-in for industry leading animation software, Autodesk Maya, that allows KUKA robots to be programmed by anyone who knows how to animate inside Maya \cite[]{Animatin29:online}: a robot program can be created by simply dragging the \gls{3d} model of the robot through space in the virtual world and setting keyframes. Another company, SISU Cinema Robotics, guide the robot with the motion of the hand using a joystick \cite[]{SISUCine24:online} \\

% https://dakona.co.uk/top-tips-for-drone-cinematography/
\noindent Drone filming and aerial photography presents a wide range of benefits and opportunities to businesses and brands looking to capture stunning aerial imagery and to produce incredible new perspectives \cite[]{TopTipsf86:online}. There can be quite a steep initial learning curve when it comes to getting to grips with drone technology. Furthermore, it is important to use equipment that is both easy to operate and will aid the goals to capture high-quality content to include in the videos. \\

\noindent As well as becoming a decent drone pilot, to make sure that your equipment is correctly set up to ensure that the footage is correctly exposed is needed. As it is important to understand how to fly smoothly and consistently to capture professional and smooth looking aerial footage. In fact, not every position of the drone are visually interesting angles, as sometimes it is about understanding composition and depth that makes all of the difference. For the success of the video shooting is extremely crucial look for a specific angle that seems unique, cinematic, and suggests that will hold the attention of the audience. A lot of drones have additional features that help pilots capture great looking footage, such as centre points that help frame shots. Additionally, filters can be added to certain drone cameras, allowing them to control the amount of light entering the lens without compensating with shutter speed. \\

\noindent Our goal is being able to control a drone using just the motion of a hand for shooting, without the use of a joystick. The system can also be used to program a trajectory easily. This can be very interesting because it is an intuitive system. Basically, no experience is required in piloting. In addition, potentially the one who shoots could also be the actor. In spite of that, ease of use does not imply that the system does not require attention: it is quite simple to get caught up in the task at hand, and completely lose track of the flight time. Some drones, such as DJI, will begin automatically landing when the battery begins to get low, however there are still a lot of other drones that do not have this intelligence and will literally crash out of the sky when it runs out of battery! Most crashes are actually caused by battery voltage drop \cite[]{WhatHapp70:online}. Do not moderate the flight time and do not keep a close eye on the battery levels, can lead to disastrous accidents \cite[]{ListofUA81:online}. \\

\noindent In order to achieve this goal, research has been carried out in the literature to see if a hand tracking system already exists. There is some solution such as \cite[]{oikonomidis2011efficient} where, with the extensive experiments with a prototype GPU-based implementation of the proposed method, demonstrates that accurate and robust \gls{3d} tracking of hand articulations can be achieved in near real-time (15Hz), using a Kinect sensor. A more recent work \cite[]{OculusCo32:online} marking another important \gls{vr} input milestone, in the evolution of \gls{vr} input, with the announcement of hand tracking on Oculus Quest enabling natural interaction in using the own hands on an all-in-one standalone device, no extra hardware required. All without the need for a controller, external sensors, gloves, or a PC to power it. And finally, one of the latest research of Google Group research \cite[]{zhang2020mediapipe} a solution that does not require any additional hardware and performs in real-time on mobile devices (the one actually used in this project and widely spoken in the literature chapter \ref{chap:stateoftheart}). Thanks to this system it was possible to build a \gls{dnn} to recognize specific hand gestures. The orientation of a specific gesture (called "detect gesture") was also estimated in order to obtain also information on depth. Through hand gesture recognition and orientation estimation, a pipeline to detect a \gls{3d} trajectory has been defined. However, this trajectory $g$ is disturbed by estimation errors. Therefore, two different data fitting algorithms were applied on the trajectory $g$: first $3$ splines and then $3$ ridge regression, in both cases for each components $x$,$y$ and $z$. This phase allowed to go from trajectory $g$ to $g_{smooth}$. \\

\noindent As a \gls{poc}, the captured trajectory was launched first on a drone, in simulation, implemented in the \gls{ros} framework. After, the DJI Ryze Tello drone (see Sec. \ref{subsec:tello}) was used to test the application in real life. DJITelloPy is the DJI Tello drone python interface, used in the project to make the application communicating with the drone. The trajectory veracity is visible to the naked eye. The correctness of the fixed dimension of the trajectory was extremely important for the projectâ€™s purpose since, if the range of action in which the drone operates is uncontrolled, then it could get dangerous for those around it. \\

\noindent The project's objective is reached with success and the entire pipeline for the acquisition of the trajectory can be exploited in \gls{ar} and \gls{vr} scenarios as it would allow people to interact with virtual objects and/or perform actions.